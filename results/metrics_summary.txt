LogisticRegression:
  cv_f1_mean: 0.8997
  cv_f1_std: 0.0054
  train_acc: 0.9563
  test_acc: 0.8800
  precision: 0.8793
  recall: 0.8800
  f1: 0.8796
  classification_report:               precision    recall  f1-score   support

           0       0.83      0.81      0.82        68
           1       0.90      0.92      0.91       132

    accuracy                           0.88       200
   macro avg       0.87      0.86      0.87       200
weighted avg       0.88      0.88      0.88       200

  confusion_matrix: [[55, 13], [11, 121]]

RandomForest:
  cv_f1_mean: 0.8961
  cv_f1_std: 0.0089
  train_acc: 1.0000
  test_acc: 0.8900
  precision: 0.8905
  recall: 0.8900
  f1: 0.8876
  classification_report:               precision    recall  f1-score   support

           0       0.90      0.76      0.83        68
           1       0.89      0.95      0.92       132

    accuracy                           0.89       200
   macro avg       0.89      0.86      0.87       200
weighted avg       0.89      0.89      0.89       200

  confusion_matrix: [[52, 16], [6, 126]]

XGBoost:
  cv_f1_mean: 0.9107
  cv_f1_std: 0.0118
  train_acc: 1.0000
  test_acc: 0.8900
  precision: 0.8891
  recall: 0.8900
  f1: 0.8892
  classification_report:               precision    recall  f1-score   support

           0       0.86      0.81      0.83        68
           1       0.90      0.93      0.92       132

    accuracy                           0.89       200
   macro avg       0.88      0.87      0.88       200
weighted avg       0.89      0.89      0.89       200

  confusion_matrix: [[55, 13], [9, 123]]

Best model: XGBoost
