{
  "best_model": "XGBoost",
  "metrics": {
    "LogisticRegression": {
      "best_params": {
        "C": 1,
        "solver": "liblinear"
      },
      "accuracy": 0.51,
      "precision": 0.5101461038961038,
      "recall": 0.51,
      "f1": 0.5082296266559615,
      "classification_report": "              precision    recall  f1-score   support\n\n           0       0.51      0.57      0.54       100\n           1       0.51      0.45      0.48       100\n\n    accuracy                           0.51       200\n   macro avg       0.51      0.51      0.51       200\nweighted avg       0.51      0.51      0.51       200\n",
      "confusion_matrix": [
        [
          57,
          43
        ],
        [
          55,
          45
        ]
      ]
    },
    "RandomForest": {
      "best_params": {
        "max_depth": 5,
        "n_estimators": 100
      },
      "accuracy": 0.525,
      "precision": 0.5254297629946089,
      "recall": 0.525,
      "f1": 0.5229846099771536,
      "classification_report": "              precision    recall  f1-score   support\n\n           0       0.52      0.59      0.55       100\n           1       0.53      0.46      0.49       100\n\n    accuracy                           0.53       200\n   macro avg       0.53      0.53      0.52       200\nweighted avg       0.53      0.53      0.52       200\n",
      "confusion_matrix": [
        [
          59,
          41
        ],
        [
          54,
          46
        ]
      ]
    },
    "XGBoost": {
      "best_params": {
        "learning_rate": 0.1,
        "max_depth": 3,
        "n_estimators": 50
      },
      "accuracy": 0.525,
      "precision": 0.5251231032057079,
      "recall": 0.525,
      "f1": 0.5244174113288779,
      "classification_report": "              precision    recall  f1-score   support\n\n           0       0.52      0.56      0.54       100\n           1       0.53      0.49      0.51       100\n\n    accuracy                           0.53       200\n   macro avg       0.53      0.53      0.52       200\nweighted avg       0.53      0.53      0.52       200\n",
      "confusion_matrix": [
        [
          56,
          44
        ],
        [
          51,
          49
        ]
      ]
    }
  }
}